# Multimodal Emotion Recognition - Baseline Configuration
# Based on the optimal template from ablation_with_speaker2.yaml
# Uses audio + text with cross-attention fusion


# Base template for multimodal experiments
template_config: &template
  # Random seeds for multiple runs (for statistical significance)
  seeds: [42, 123, 456]  # Will run 3 times and average results

  # Training hyperparameters (from optimal config)
  learning_rate: 9e-3
  weight_decay: 5e-6
  num_epochs: 30
  batch_size: 64
  dropout: 0.1

  # Dataset settings
  train_dataset: "IEMO"
  evaluation_mode: "cross_corpus"

  # Multimodal settings
  modality: "both"  # "audio", "text", or "both"
  audio_dim: 768
  text_model_name: "bert-base-uncased"
  freeze_text_encoder: true
  text_max_length: 128

  # Fusion settings
  fusion_type: "cross_attention"  # "cross_attention", "concat", "gated"
  fusion_hidden_dim: 512
  num_attention_heads: 8

  # Model architecture
  hidden_dim: 1024
  num_classes: 4

  # Class weights
  class_weights:
    neutral: 1.0
    happy: 1.0
    sad: 1.0
    anger: 1.0

  # Curriculum learning settings (from optimal config)
  use_curriculum_learning: true
  curriculum_epochs: 15
  curriculum_pacing: "sqrt"
  curriculum_type: "difficulty"
  difficulty_method: "euclidean_distance"

  # Advanced features (from optimal config)
  use_difficulty_scaling: false
  use_speaker_disentanglement: true

  # Loss function settings (works well for audio-only)
  loss_temperature: 2000  # High temperature for audio-only
  focal_gamma: 2.0
  post_curriculum_dropout: 0.6  # Dropout after curriculum for audio-only

  wandb_project: "Multimodal_Fusing_Emotion_IEMO"

  # Expected VAD values for difficulty calculation
  expected_vad:
    0: [3.0, 2.5, 3.0]  # neutral
    1: [4.0, 3.8, 3.8]  # happy
    2: [1.8, 2.2, 2.0]  # sad
    3: [1.8, 4.2, 4.0]  # anger

experiments:
  - <<: *template
    name: "Multimodal Full System IEMO"
    modality: "both"
    fusion_type: "cross_attention"
    # Lower dropout and disable difficulty scaling for fusion models
    dropout: 0.2
    loss_temperature: 1.0
    post_curriculum_dropout: 0.2
    use_difficulty_scaling: false

  - <<: *template
    name: "Audio Only Baseline IEMO"
    modality: "audio"
    # Keep audio-only settings (works well)

  - <<: *template
    name: "Text Only Baseline IEMO"
    modality: "text"
    # Lower dropout for text-only
    dropout: 0.2
    loss_temperature: 1.0
    post_curriculum_dropout: 0.2

  - <<: *template
    name: "Multimodal Concat Fusion IEMO"
    modality: "both"
    fusion_type: "concat"
    # Lower dropout for fusion models
    dropout: 0.2
    loss_temperature: 1.0
    post_curriculum_dropout: 0.2

  - <<: *template
    name: "Multimodal Gated Fusion IEMO"
    modality: "both"
    fusion_type: "gated"
    # Lower dropout for fusion models
    dropout: 0.2
    loss_temperature: 1.0
    post_curriculum_dropout: 0.2
